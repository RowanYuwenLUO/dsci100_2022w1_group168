{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "030a00f5-2b38-4505-a95a-8509581bc1a8",
   "metadata": {},
   "source": [
    "##    <center> DSCI 100 Group Project Report\n",
    "    \n",
    "**Group 168**\n",
    "\n",
    "**Anjali Dajee**\n",
    "\n",
    "**Ross Tomita**\n",
    "\n",
    "**Yuwen Luo**<center>\n",
    "    \n",
    "    \n",
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4955ca3e-222e-46a6-b297-3e30571d83f1",
   "metadata": {},
   "source": [
    "# <center>Investigating pulsar star data to find an accurate predictive model using the KNN algorithm: exploratory study <center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12c8a9dd-00c5-4915-8d76-208b77b97a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de28098-6d27-4ee4-9607-0aedc67894fc",
   "metadata": {},
   "source": [
    "Pulsars are neutron stars that form when a star collapses within itself and eventually explodes, creating a supernova. As the pulsars rotate, they produce a broadband radio emission that can be detected from earth using a large dish antenna and a radio. Since each pulsar’s emission is slightly different during each rotation, a singular signal detection is made by averaging several rotation emissions of the star (Lyon et al.)  However, most detections are actually interfering man-made radio signals, and not actual pulsars. To determine whether a detection is truly a pulsar, other variables must be considered. The discovery of pulsars has allowed scientists to observe neutron stars for the first time, as well as test some of the conditions of Einstein’s theory of relativity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3be6bf-f081-4329-b49f-080cd4f89683",
   "metadata": {},
   "source": [
    "In the current study, we will explore the HTRU2 dataset which describes samples of known pulsar and non-pulsar stars. This dataset is described by 9 different attributes in which 8 quantitative variables come from two different curves:\n",
    "\n",
    "- The first is an `average integrated pulse profile` of a single pulsar star. To account for minor discrepancies in each pulse, several emissions are averaged and put together to create a single pulse profile for a star. \n",
    "\n",
    "- The second curve accounts for delay when pulses arrive at differing time across different radio frequencies. This delay, or dispersion, can be fit and compensated for in astronomers’ calculations, however there is always a certain measure of uncertainty. This is accounted for in the “dispersion-measure-signal-to-noise-ratio” `(DM-SNR) curve`. \n",
    "\n",
    "From these two curves, 8 numerical features can be calculated and standardized. From the integrated pulse profile, we get;  `Mean, Excess Kurtosis, Skewness, and Standard Deviation`. From the DM-SNR curve, the `same four variables` can be acquired. \n",
    "\n",
    "The ninth variable, `Class`, is a categorical variable with 2 different levels, which is what we will be trying to predict (Scaife). \n",
    "<blockquote>\n",
    "    0 represents negative examples (false detections for pulsar starts);\n",
    "</blockquote>\n",
    "<blockquote>\n",
    "    1 represents positive examples (true detections for pulsar starts).\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e957caf-3f29-4a88-b7fc-2caf2e2038bd",
   "metadata": {},
   "source": [
    "We will use these in our analysis to determine **whether any of these can be used to accurately classify whether a detection is a pulsar star or not**. We have also taken into consideration that the number of true pulsar stars is a minority positive class, while the number of false detections is a majority negative class. This information will be useful when sampling  the training set from the original dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13598ae-dbf3-4d15-a157-237b9d2f9745",
   "metadata": {},
   "source": [
    "_____________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99705471-c4f7-463e-bfcb-60b145642834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Methods & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967fb711-8215-4a04-875b-43384ef3f3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.1 Import data, tidy data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169a2364-df7b-46e0-95b1-648637c3c270",
   "metadata": {},
   "source": [
    "## 2.2 Split data into training and testing sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acff5f98-e0b7-4da5-a0a5-e3177886418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.3 Pre-processing the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9adddb-f952-4a5e-a9f0-6f24d7e06187",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.3.1 Resolve imbalance problem by sampling down the 0 (negative) class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2be93a8-f704-471f-87a0-c90bf5cd546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.3.2 Scale the training set after sampling down it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eff04f-ad49-4b84-8c25-a7984d35427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.3.3 Visualize the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbc319f-f935-4cf0-9525-252629e8fb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.4 Data Analysis: K-NN Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db719393-295d-4e03-9d30-f473df041ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.4.1 Classification: using predictors chosen from Forward selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24791b21-d8e6-4038-91b3-af82841d6c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.4.2 Classification: using predictors chosen from Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa41c92-5ce8-49bf-948a-376271b6528e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db670cb2-faae-4e59-a2d4-ff89e9bfb01c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbba2ad-dbb9-433e-9d32-5386c21ac25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Multicollinearity Problem and Additional Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5709fb67-d563-4030-b47b-4e1a8369beba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.1  Multicollinearity Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff05f431-a26d-4f17-95c9-551d6a5725b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.2 Additional Analysis with PCA (Principal Component Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f408b1-8c42-4184-8d56-147d31719834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18cc2ebb-962e-4eb8-9644-b0d1c262de54",
   "metadata": {},
   "source": [
    "________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33038033-5a0b-4e64-9f2e-5bc3321d9670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9493c9e2-d027-4337-9e68-d58dbf91e923",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.1 Conclusions and Potential Limitations for Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42bfe1f-23a7-483b-ad16-fe14e71c5ee7",
   "metadata": {},
   "source": [
    "## 4.2 Impact and Future Questions\n",
    "\n",
    "The question of whether the 96% accuracy is high enough to use in the real world depends on what this data is being used for. For general interest and scientific exploration, it’s a fairly good number and holds a high certainty. However, if this data were to be used for projects involving human space exploration, for example, or even simply in calculations involving space projects, that 4% uncertainty can pose a big risk to safety. Despite the accuracy being an objectively high percent, there are some instances where even a small amount of risk can be deadly. However, pulsar star data is generally used to test mathematical conditions, and as such, the accuracy is sufficient.\n",
    "\n",
    "This data analysis could help promote the automation of pulsar classification, which would save astronomers a lot of time and effort. At present, each data point must be manually analyzed, and seeing as there’s upwards of 10,000 entries, this task is very time consuming. Using a model to predict the classification of pulsar stars would allow scientists to spend more time applying this data to further research. \n",
    "\n",
    "Our classification can lead to future questions, such as whether we can further classify stars using the same model. For example, differentiating between pulsars, stars, white dwarfs, black holes, and more. With more resources and knowledge of classification, this is a potential question we can one day explore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c60752-464d-48c4-a9b6-f1c5e8998f23",
   "metadata": {},
   "source": [
    "________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f8c28c-583d-490c-87ab-1fb2ae01660b",
   "metadata": {},
   "source": [
    "# WORKS CITED\n",
    "\n",
    "R. J. Lyon, B. W. Stappers, S. Cooper, J. M. Brooke, J. D. Knowles, Fifty Years of Pulsar Candidate \n",
    "Selection: From simple filters to a new principled real-time classification approach, Monthly Notices of the Royal Astronomical Society 459 (1), 1104-1123, DOI: 10.1093/mnras/stw656\n",
    "\n",
    "R. J. Lyon, HTRU2, DOI: 10.6084/m9.figshare.3080389.v1.\n",
    "\n",
    "Scaife, A. (n.d.). CSC2019 - Introduction to Machine Learning. CSC2019 - Introduction to machine learning. Retrieved December 4, 2022, from https://as595.github.io/classification/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79918a0d-ac75-4a85-9099-3ac0dc23ae94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
